{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import ingest\n",
    "import dotenv\n",
    "import pandas as pd\n",
    "from config import load_config as load, load_db_opts, load_polygon_opts\n",
    "from scrap import _scrap_sp_500_constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load local dotenv (because not dockerize for now - can be added to image or passed at docker run)\n",
    "dotenv.load_dotenv(utils.ENV_DOCKER_FILE)\n",
    "dotenv.load_dotenv(utils.ENV_SECRETS_FILE)\n",
    "config = load(load_db_opts, load_polygon_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tickers\n",
    "# get each tickers earning dates\n",
    "# roll 5 days before earning dates values\n",
    "# get minute graphs for  | 5 days roll | > 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tickers\n",
    "from scrap import _scrap_sp_500_constituents\n",
    "\n",
    "sp500_constituents = _scrap_sp_500_constituents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get each tickers earning dates\n",
    "from scrap import _scrap_previous_earnings\n",
    "all_earning_dates = pd.DataFrame()\n",
    "\n",
    "for _, row in sp500_constituents.head(5).iterrows():\n",
    "    symbol = row[\"symbol\"]\n",
    "    curr_df = _scrap_previous_earnings(symbol)\n",
    "    all_earning_dates = pd.concat([all_earning_dates, curr_df])\n",
    "\n",
    "# filter on past earning dates only\n",
    "from datetime import datetime\n",
    "\n",
    "earning_dates = all_earning_dates[all_earning_dates[\"earnings_date\"] < datetime.now()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['symbol', 'company', 'earnings_date', 'eps_estimates', 'eps_reported',\n",
      "       'surprise_percent'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(earning_dates.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- ABT: No data found for this date range, symbol may be delisted\n",
      "Index(['date', 'open', 'high', 'low', 'close', 'volume', 'dividends',\n",
      "       'stock_splits', 'symbol'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# get data for each tickers\n",
    "from datetime import timedelta\n",
    "from scrap import _scrap_daily_prices_for_earnings\n",
    "\n",
    "all_prices_around_earnings = pd.DataFrame()\n",
    "\n",
    "for _, row in earning_dates.iterrows():\n",
    "    symbol = row[\"symbol\"]\n",
    "    earnings_date = row[\"earnings_date\"]\n",
    "    earnings_date_5_days_before = earnings_date - timedelta(days=5)\n",
    "\n",
    "    curr_df = _scrap_daily_prices_for_earnings(symbol, earnings_date_5_days_before, earnings_date)\n",
    "    \n",
    "    all_prices_around_earnings = pd.concat([all_prices_around_earnings, curr_df])\n",
    "\n",
    "print(all_prices_around_earnings.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'open', 'high', 'low', 'close', 'volume', 'dividends',\n",
      "       'stock_splits', 'symbol', 'company', 'earnings_date', 'eps_estimates',\n",
      "       'eps_reported', 'surprise_percent'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# join earning dates & prices around earnings\n",
    "earnings_with_lagging_prices = pd.merge(all_prices_around_earnings, earning_dates, left_on=[\"symbol\", \"date\"], right_on=[\"symbol\", \"earnings_date\"], how=\"left\")\n",
    "print(earnings_with_lagging_prices.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# transform dates to day dates\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m earning_dates[\u001b[39m\"\u001b[39m\u001b[39mearnings_day\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m earning_dates[\u001b[39m\"\u001b[39;49m\u001b[39mearnings_date\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mdt\u001b[39m.\u001b[39;49mdate\u001b[39m.\u001b[39;49mstr\n\u001b[1;32m      3\u001b[0m all_prices_around_earnings[\u001b[39m\"\u001b[39m\u001b[39mday\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m all_prices_around_earnings[\u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39mdate\u001b[39m.\u001b[39mstr\n\u001b[1;32m      5\u001b[0m \u001b[39m# merge earning dates & prices around earnings\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Projects/finexplore/venv/lib/python3.10/site-packages/pandas/core/generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5568\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5569\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5570\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5571\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5572\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5573\u001b[0m ):\n\u001b[1;32m   5574\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5575\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "File \u001b[0;32m~/Documents/Projects/finexplore/venv/lib/python3.10/site-packages/pandas/core/accessor.py:182\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     \u001b[39m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessor\n\u001b[0;32m--> 182\u001b[0m accessor_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor(obj)\n\u001b[1;32m    183\u001b[0m \u001b[39m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[39m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[39m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[39m# NDFrame\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m~/Documents/Projects/finexplore/venv/lib/python3.10/site-packages/pandas/core/strings/accessor.py:177\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[1;32m    175\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marrays\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstring_\u001b[39;00m \u001b[39mimport\u001b[39;00m StringDtype\n\u001b[0;32m--> 177\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_dtype \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate(data)\n\u001b[1;32m    178\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_categorical \u001b[39m=\u001b[39m is_categorical_dtype(data\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_string \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(data\u001b[39m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[0;32m~/Documents/Projects/finexplore/venv/lib/python3.10/site-packages/pandas/core/strings/accessor.py:231\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    228\u001b[0m inferred_dtype \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39minfer_dtype(values, skipna\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m inferred_dtype \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m allowed_types:\n\u001b[0;32m--> 231\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan only use .str accessor with string values!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "# transform dates to day dates\n",
    "earning_dates[\"earnings_day\"] = earning_dates[\"earnings_date\"].dt.date.to_string()\n",
    "all_prices_around_earnings[\"day\"] = all_prices_around_earnings[\"date\"].dt.date.to_string()\n",
    "\n",
    "# merge earning dates & prices around earnings\n",
    "earnings_with_lagging_prices = pd.merge(earning_dates, all_prices_around_earnings, left_on=[\"symbol\", \"earnings_day\"], right_on=[\"symbol\", \"day\"], how=\"right\")\n",
    "print(earnings_with_lagging_prices.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date            datetime64[ns]\n",
      "open                   float64\n",
      "high                   float64\n",
      "low                    float64\n",
      "close                  float64\n",
      "volume                 float64\n",
      "dividends              float64\n",
      "stock_splits           float64\n",
      "symbol                  object\n",
      "day                     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(all_prices_around_earnings.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symbol                      object\n",
      "company                     object\n",
      "earnings_date       datetime64[ns]\n",
      "eps_estimates              float64\n",
      "eps_reported               float64\n",
      "surprise_percent            object\n",
      "earnings_day                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(earning_dates.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       symbol        company       earnings_date  eps_estimates  eps_reported  \\\n",
      "0         MMM     3M Company 2023-07-25 02:00:00           1.72          2.17   \n",
      "1         MMM     3M Company 2023-04-25 02:00:00           1.58          1.97   \n",
      "2         MMM     3M Company 2023-01-24 01:00:00           2.36          2.28   \n",
      "3         MMM     3M Company 2022-10-25 02:00:00           2.60          2.69   \n",
      "4         MMM     3M Company 2022-07-26 02:00:00           2.42          2.48   \n",
      "...       ...            ...                 ...            ...           ...   \n",
      "147131   ABMD  Abiomed, Inc. 1998-05-28 00:00:00          -0.08         -0.09   \n",
      "147132   ABMD  Abiomed, Inc. 1998-01-28 00:00:00          -0.05         -0.07   \n",
      "147133   ABMD  Abiomed, Inc. 1995-05-16 00:00:00          -0.01           NaN   \n",
      "147134   ABMD  Abiomed, Inc. 1995-01-24 00:00:00          -0.01           NaN   \n",
      "147135   ABMD  Abiomed, Inc. 1994-10-26 00:00:00          -0.01           NaN   \n",
      "\n",
      "       surprise_percent earnings_day       date        open        high  \\\n",
      "0                +26.16   2023-07-25 2023-07-19  102.849998  103.760002   \n",
      "1                +24.37   2023-04-25 2023-07-19  102.849998  103.760002   \n",
      "2                 -3.52   2023-01-24 2023-07-19  102.849998  103.760002   \n",
      "3                 +3.44   2022-10-25 2023-07-19  102.849998  103.760002   \n",
      "4                 +2.64   2022-07-26 2023-07-19  102.849998  103.760002   \n",
      "...                 ...          ...        ...         ...         ...   \n",
      "147131            -9.09   1998-05-28 1994-10-25    3.062500    3.125000   \n",
      "147132           -27.27   1998-01-28 1994-10-25    3.062500    3.125000   \n",
      "147133             +100   1995-05-16 1994-10-25    3.062500    3.125000   \n",
      "147134             +100   1995-01-24 1994-10-25    3.062500    3.125000   \n",
      "147135           +66.67   1994-10-26 1994-10-25    3.062500    3.125000   \n",
      "\n",
      "               low       close     volume  dividends  stock_splits         day  \n",
      "0       102.599998  103.480003  2088900.0        0.0           0.0  2023-07-19  \n",
      "1       102.599998  103.480003  2088900.0        0.0           0.0  2023-07-19  \n",
      "2       102.599998  103.480003  2088900.0        0.0           0.0  2023-07-19  \n",
      "3       102.599998  103.480003  2088900.0        0.0           0.0  2023-07-19  \n",
      "4       102.599998  103.480003  2088900.0        0.0           0.0  2023-07-19  \n",
      "...            ...         ...        ...        ...           ...         ...  \n",
      "147131    2.875000    3.062500    18000.0        0.0           0.0  1994-10-25  \n",
      "147132    2.875000    3.062500    18000.0        0.0           0.0  1994-10-25  \n",
      "147133    2.875000    3.062500    18000.0        0.0           0.0  1994-10-25  \n",
      "147134    2.875000    3.062500    18000.0        0.0           0.0  1994-10-25  \n",
      "147135    2.875000    3.062500    18000.0        0.0           0.0  1994-10-25  \n",
      "\n",
      "[147136 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "print(earnings_with_lagging_prices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
